---
title: "ploidy_snp_props_simulation"
author: "Florian"
date: "`r Sys.Date()`"
output: html_document
---


# Simulation of read_allele_proportions

This simulator allows me to simulate different ploidies, from 2n to 4n. This simulator sort of realistically simulates data sampled from rad-seq data.

The realism part comes from the simulation of read depth. For RAD-seq a exponential distribution is reasonable. A geometric distribution may be better as read depth is discrete. or rather a natural number set. 


## Function definition

```{r}
# Function to simulate allele proportions for a single SNP
simulate_snp <- function(mean_depth, n_sites, ploidy, biallelic_freqs,freqs_prob) {
  # Sample read depth from exponential distribution
  read_depth <- round(rexp(1, rate = 1/mean_depth), 0)
  
  # Sample biallelic frequency state based on ploidy
  biallelic_state <- sample(1:length(biallelic_freqs), size = 1, prob = freqs_prob)
  #print("START")

  # Extract corresponding biallelic frequencies
  freq_a <- biallelic_freqs[[biallelic_state]][1]
  freq_b <- biallelic_freqs[[biallelic_state]][2]
  

  # Sample alleles based on frequencies
  alleles <- sample(c("A", "B"), size = read_depth, prob = c(freq_a, freq_b), replace = TRUE)
  
  alleles_a <- sum(alleles == "A")
  alleles_b <- sum(alleles == "B")
  
  # Estimate allele proportions
  prop_a <- alleles_a / read_depth
  prop_b <- alleles_b / read_depth
  
  #print(alleles)
  #print(c(prop_a, prop_b))
  
  # Return allele proportions
  return(c(biallelic_state,read_depth,alleles_a,alleles_b,prop_a, prop_b))
}

snp_simulator_big <- function(current_ploidy, mean_depth, n_sites, freqs_prob) {
  freqs_prob <- freqs_prob
  mean_depth <- mean_depth
  current_ploidy <- current_ploidy
  n_sites <- n_sites
  
  
  # Define biallelic frequencies for different ploidies
  biallelic_freqs_diploid <- list(c(0.5, 0.5))
  biallelic_freqs_triploid <- list(c(0.33, 0.66))
  biallelic_freqs_tetraploid <- list(c(0.5,0.5),c(0.25, 0.75))
  

  # Get corresponding biallelic frequencies
  if (current_ploidy == 2) {
    biallelic_freqs <- biallelic_freqs_diploid
    freqs_prob <- 1
  } else if (current_ploidy == 3) {
    biallelic_freqs <- biallelic_freqs_triploid
    freqs_prob <- 1
  } else if (current_ploidy == 4){
    biallelic_freqs <- biallelic_freqs_tetraploid
    #freqs_prob <- c(0.3,0.7)
  }
  
  # Initialize empty matrix to store allele proportions
  #all_props <- matrix(nrow = n_sites, ncol = 5)
  all_props <- data.frame()
  
  # Simulate for each SNP site
  for (i in 1:n_sites) {
    
    # Simulate and store allele proportions
    props <- simulate_snp(mean_depth, 1, current_ploidy, biallelic_freqs,freqs_prob)
    #all_props[i, ] <- props
    all_props <- rbind(all_props,props)
  }
  
  colnames(all_props) <- c("biallelic_state","read_depth","allele_a_reads","allele_b_reads","allele_prop_a","allele_prop_b")
  
  all_props$allele_diff <- all_props$allele_prop_a - all_props$allele_prop_b
  
  return(all_props)
}

```


# QC filtering and plotting

Here i simulate a tetraploid, with a mean depth of 20 (in my data is more like 4 :c). This is to avoid too many sites with 0 depth as that is also a possible number. In theory this allows this simulator to emulate allele drop due to sparse depth. 

10k sites is reasonable for testing. And a empirical ratio of the peak groups. In the tetraploid case you have to groups of peaks:

- 0.5 peak -> These would be big if the fixed differences among the parental genomes are low.
- 0.25/0.75 peaks -> These would be big if each of the genomes in question have high heterozygosity for some reason. High mutation rate?

The assumptions before only apply for the biallelic case which is by far the most common. Right now i dont have a way to simulate the ratio of these two peaks from the heterozygosity and divergence among parental genomes. So i just force a particular ratio between the peaks. 

In the autopollyploid case.. moost peaks should be 0.25/0.75. Not many intraspecific differences would be fixed that would be rare. 



```{r}
current_ploidy <- 4 # Tetraploid
mean_depth <- 20 # profundidad promedio?
n_sites <- 10000
freqs_prob <- c(0.3,0.7) # 2 numeros que sumen 1 en tetraploides, de resto 1. el primer numero corresponde a prporcion 0.5/0.5


all_props <- snp_simulator_big(current_ploidy, mean_depth, n_sites, freqs_prob)

minimum_allele_depth <- 5

all_props_QC <-all_props[all_props$allele_a_reads >= minimum_allele_depth & all_props$allele_b_reads >= minimum_allele_depth,]
```

Here i plot the raw frequencies of the alleles, which they would have peaks at 0.25 0.5 and 0.75. But given the distribution of read sampling there is a limitation on the range of possible values. The distribution is sort of discrete in this sense. 


```{r}
library(ggplot2)

complete_freqs <- c(all_props_QC$allele_prop_a,all_props_QC$allele_prop_b) 

ggplot(as.data.frame(complete_freqs), aes(x = complete_freqs)) +
  geom_histogram(alpha = 0.5, fill = "blue", binwidth = 0.05) +  # Adjust bins as needed
  labs(title = "Distribution of allele-snp frequencies", x = "biallelic_frequency") +
  xlim(0,1)
```

Another way of representing these distributions is to take the difference of the allelic frequencies. As the frequencies for any snp will always sum to one, no information is lost. Adding over this fact you can even sort the values firts an take the difference between the highest and the lowest value. Which would limit the distribution to positive or negative values if needed. This last option i think is of limited use.... taking the difference is useful for reducing the number of data points?, and it is technically a direct modelling of the associated error, not of the frequencies themselves. If there is any underlying bias in the distribution, there are ways to randomize. 


```{r}

n <- 10

for (i in c(1:n)) {
  inversion_vector <- sample(c(-1,1), size = length(all_props_QC$allele_diff),replace = TRUE)
  all_props_QC$allele_diff <- all_props_QC$allele_diff * inversion_vector
}

complete_freq_diff <- all_props_QC$allele_diff

ggplot(as.data.frame(complete_freq_diff), aes(x = complete_freq_diff)) +
  geom_histogram(alpha = 0.5, fill = "blue", binwidth = 0.05) +  # Adjust bins as needed
  labs(title = "Distribution of allele-snp frequencies", x = "biallelic_frequency") +
  xlim(-1,1)
```
Lo que veo es que me separa los picos de las distribuciones mas y corregir por sesgos es relativamente sencillo, el hecho de que pueda ser menor o mayor a cero hace automaticamente que la diferencia entre los picos sea como del doble....., creo que esa es la forma mas adecuada de modelarlo.... No creo que sufra por usar menos datos, la mitad de los datos para ser exactos, pero la vuelta es que esos datos son limitados el uno con el otro... hay una dependencia rara ahÃ­. 


Ahora me centro en estimar variables o incluso modelar cosas de estos datos simulados, es bueno antes de ponerme a definir los modelos a la loca. Creo que me va tocar hacer luego un monton de simulaciones.... simulaciones validas?

Primero veo el promedio de la distribucion y la varianza de esta diferencia y observo estimados rasonables. 

```{r}
mean(complete_freq_diff)
var(complete_freq_diff)
```

Luego estimo eso para cada pico

```{r}
# Function to calculate mean, variance, and absolute values
summary_by_group <- function(data, group_col, value_col) {
  # Group data by group_col
  grouped_data <- split(data[, c(group_col, value_col)], data[, group_col])
  
  # Calculate summary statistics
  summary_stats <- sapply(grouped_data, function(x) {
    c(
      mean = mean(x[, value_col]),
      variance = var(x[, value_col])#,
      #abs_values = abs(x[, value_col])
    )
  })
  
  print(summary_stats)
  # Return summary statistics as a data frame
  return(data.frame(summary_stats))
}

# Example usage
# Create sample data
data <- data.frame(group = c("A", "A", "B", "B", "C"),
                   value = c(10, 5, -8, 12, 3))

# Get summary statistics
summary_df <- summary_by_group(all_props_QC, group_col = "biallelic_state", value_col = "allele_diff")


```


The variance of the 0.25 and 0.75 peaks is exaggerated because the peaks right now are in -0.5 and 0.5. But they are the same peak. The most reasonable way to equalize everything is to take the absolute value of said peaks and the estimate the variance. The mean is expected to be close to 0 so that is OK. 

```{r}
mean(abs(all_props_QC[all_props_QC$biallelic_state == 2,c("allele_diff")]))
var(abs(all_props_QC[all_props_QC$biallelic_state == 2,c("allele_diff")]))
sd(abs(all_props_QC[all_props_QC$biallelic_state == 2,c("allele_diff")]))
```

The variance of the peaks is similar.... at least for this simulation. To be sure how to model all of this crap i would have to run many simulations with varying degrees of:

- mean read depth
- minimum allele depth / maximum too?
- proportion of 0.5/0.5 to 0.25/0.75 sites
- number of sampled sites. 

Then i need to know the mean and variance of each peak. Good god. 


## Normality of these peaks

Important question before getting into modelling with normal shit. First y plot the 0.25/0.75 peaks signals and i overlay a normal distribution with expected parameters. Is not quite right. The left hand side of the distr is underestimated and the right hand over estimated. I suspect it has to do with count-freq distribution. There is a skew in the distribution.

```{r}
outer_peaks <- abs(all_props_QC[all_props_QC$biallelic_state == 2,c("allele_diff")])

ggplot(as.data.frame(outer_peaks), aes(x = outer_peaks)) +
  geom_histogram(alpha = 0.5, fill = "blue", binwidth = 0.01) +  # Adjust bins as needed
  labs(title = "Distribution of Two Columns", x = "biallelic_frequency") +
  xlim(0,1) + 
  stat_function(fun = function(x) dnorm(x,mean = 0.5, sd = sd(outer_peaks))*30)

```
I tested fitting with MASS, it gave the expected for a normal distr not sure what was i thinking. But to note, the mean is underestimated. 


```{r}
library(MASS)
fit <- fitdistr(outer_peaks, "normal")
fit$estimate

```

The qqplot confirms that is not quite normal

```{r}
ggplot(as.data.frame(outer_peaks), aes(sample = outer_peaks)) +
  stat_qq()+
  stat_qq_line()

```

A shapiro test further confirms that is not quite normal. 

```{r}
shapiro.test(outer_peaks)
```


Veo que una distribucion normal medio no es del todo adecuada. Y tengo una idea para ajustar todo:

- Crear una distribucion discreta de la distribucion de posibles proporciones alelicas que se pueden obtener, ponderada por la frequencia de profundidad de secuenciacion. 
- Cambiar de distribucion exponencial a geometrica?
- Multiplicar esa distribucion discreta por la normal que ya he definido mas adelante. Con esas 2 cosas el fit debe ser casi que identico...


Otra opcion es ignorar este hecho y apuntar a buscar una medida que simplemente me mida el ajuste del modelo a los datos, una diferencia consistente y buena entre modelos es lo unico que busco en este caso. 

# Fitting of distributions to data

Here i can define a specific distribution. In this test i'm simulating a tetraploid case. I assume that the variance of each allele frequency peak is the same. 


```{r}
# Define individual normal distributions (replace with your estimated means and variances)
left_normal <- function(x) { dnorm(x, mean = -0.5, sd = 0.14) }
central_normal <- function(x) { dnorm(x, mean = 0, sd = 0.14) }
right_normal <- function(x) { dnorm(x, mean = 0.5, sd = 0.14) }

# Define mixing proportions (replace with estimated values, they sum to 1)
central_prop <- 0.4  # Proportion for central_normal
out_ward_prop <- (1-central_prop)/2  # Proportion for left_normal and right_normal


# Mixture density function
mixture_density <- function(x) {
  out_ward_prop * left_normal(x) + central_prop * central_normal(x) + out_ward_prop * right_normal(x)
}



```


Sample from this mixture density distribution


```{r}

xrange <- 1 # function range from 0 (implicit) to x
N <- 10000 # number of samples
#b <- -2.16
#mx <- 35.48
#sigma <-  147.17

xy <- data.frame(proposed = runif(N, min = -1, max = xrange))

xy$fit <- mixture_density(x = xy$proposed)

xy$random <- runif(N, min = 0, max = 1)

maxDens <- max(xy$fit)

xy$accepted <- with(xy, random <= fit/maxDens)
# retain only those values which are "below" the custom distribution
xy <- xy[xy$accepted, ]

hist(xy$proposed, freq = FALSE, breaks = 100, col = "light grey")
# multiply by 130 to make it look fit nicely
curve(mixture_density(x)/(maxDens * 1),
      from = -1, to = 1, add = TRUE, col = "red", lwd = 2)
```

Quiero ver la diferencia entre la varianza estimada de la distribucion completa y la varianza estimada de la distribucion sampleada

```{r}
mean(xy$proposed)
var(xy$proposed)
sd(xy$proposed)
```





```{r}
library(ggplot2)

#complete_freqs_diff <- c(all_props_QC$allele_prop_a-all_props_QC$allele_prop_b)

#complete_freq_diff

ggplot(as.data.frame(complete_freq_diff), aes(x = complete_freq_diff)) +
  geom_histogram(alpha = 0.5, fill = "blue", binwidth = 0.01) +  # Adjust bins as needed
  labs(title = "Distribution of Two Columns", x = "biallelic_frequency") +
  xlim(-1,1) + 
  stat_function(fun = function(x) mixture_density(x)*60)
```


## fitting test

Fitting my own custom distribution to the distribution of allele differences. 

```{r}

# Define individual normal distributions (replace with your estimated means and variances)
left_normal <- function(x,sdev) { dnorm(x, mean = -0.5, sd = sdev) }
central_normal <- function(x,sdev) { dnorm(x, mean = 0, sd = sdev) }
right_normal <- function(x,sdev) { dnorm(x, mean = 0.5, sd = sdev) }

# Define mixing proportions (replace with estimated values, they sum to 1)
central_prop <- 0.4  # Proportion for central_normal
out_ward_prop <- (1-central_prop)/2  # Proportion for left_normal and right_normal


# Mixture density function
mixture_density <- function(x,sdev,central_prop) {
  (1-central_prop)/2 * left_normal(x,sdev) + central_prop * central_normal(x,sdev) + (1-central_prop)/2 * right_normal(x,sdev)
}


library(MASS)
fit <- fitdistr(complete_freq_diff, mixture_density, list(sdev=0.1,central_prop=0.3))
fit$estimate

```


I redo the overlay graph to check if with the fitted parameters the fit is better and the change is barely noticeable

```{r}
library(ggplot2)


ggplot(as.data.frame(complete_freq_diff), aes(x = complete_freq_diff)) +
  geom_histogram(alpha = 0.5, fill = "blue", binwidth = 0.01) +  # Adjust bins as needed
  labs(title = "Distribution of Two Columns", x = "biallelic_frequency") +
  xlim(-1,1) + 
  stat_function(fun = function(x) mixture_density(x, 0.1451268,0.4118683)* 60)
```
# ks test testing

First generate a fit for a single normal corresponding to the diploid scenario

```{r}
diploid_fit <- fitdistr(complete_freq_diff, "normal")
diploid_fit$estimate
```




## Functions to generate custom CDFs

In order to use the ks.test i need to create not only the probability density function but the cumulative distribution function too, which is done by integrating. The CDF is an integral. 

custom_cdf_3 is the CDF of my custom distr. I fit that shit and i see that the D value is 0.039.



```{r}
library(dgof)

custom_cdf_3 <- function(val, mixture_density, sdev, central_prop){
  probs <- c()
  for (valor in val){
    prob_val <- integrate(function(x) mixture_density(x,sdev, central_prop), -Inf, valor)$value  
    probs <- c(probs,prob_val)
  }
  
  return(probs)
}

ks.test(complete_freq_diff, function(x) custom_cdf_3(x, mixture_density,0.1451268,0.4118683))

```

custom_cdf_4 is the CDF of a normal distribution distr. I fit that shit and i see that the D value is 0.071. A higher value indicates higher error. So my custom distribution fits better.

```{r}

custom_cdf_4 <- function(val, dnorm, mean, sd){
  probs <- c()
  for (valor in val){
    prob_val <- integrate(function(x) dnorm(x,mean, sd), -Inf, valor)$value  
    probs <- c(probs,prob_val)
  }
  
  return(probs)
}

ks.test(complete_freq_diff, function(x) custom_cdf_4(x, dnorm,-0.006089245,0.381195036), simulate.p.value = TRUE, B=1000)

```


## Fit testing of specific models

```{r}
#library(dgof)

tetraploid_model <- function(x) custom_cdf_3(x, mixture_density,0.1451268,0.4118683)
diploid_model <- function(x) custom_cdf_4(x, dnorm,-0.006089245,0.381195036)

```

```{r}
ks.test(complete_freq_diff, tetraploid_model)
```

```{r}

ks.test(complete_freq_diff, diploid_model)
```




There is a differnces in the D estatistic and also in the p value, the tetraploid model fits better.... Next step is to make a ton of simulations and automatic testing of the limits of the use of this approach. To see how robust it is.  The simluation would entail:


- mean read depth
  - 2, 5, 10, 20, 50, 100
- minimum allele depth / maximum too?
  - 2, 5, 10, 20
  - effect on ploidy signals
- Ploidy
  - proportion of 0.5/0.5 to 0.25/0.75 sites
      10 values between 0 to 1. 
  - Ploidies higher than 4n up to 6 to 8??
      - Generalization of models and simulations aaaaaa
- number of sampled sites. 
      - 100, 1000, 10000, 100000, million


PCA idea for ploidy clustering -> just do a PCA on the allele freqs doesnt go beyond that. 



# MAE fit testing

Here i define a function to estimate mean absolute error from the data

```{r}

```



# Towards a precise PDF of bialleic data

After thinking for a while the final distribution of the simulated PDF is a sum of discrete PMFs, each PMF is defined by a depth value which is defined by the geometric distribution and by the proportion of peaks, and by the likelihoods of the peaks themselves. 


1- First estimate the depth distribution
2. For each depth separate the frequency of peak type by the proportion of peaks that is defined as a parameter in the distribution. 
3. For each peak type, estimate the PMF of the possible observed frequency values that are defined by the read depth. Ignore frequencies of 0 and 1. The estimation is a linear interpolation, that is easily solved in a system of equations. Each PMF is a proper PMF
4. Sum all of the PMFs, and ponder each sum multyplying by the frequency associated to each PDF. 
5. Normalize the sum of PMFs so that it becomes a proper PMF. 

That should be the final distribution of biallelic frequencies. 

The only things needed to define this theorethical distribution are:

- Geometric distribution of depths, or even the empirical distribution
- Peak proportion, that should be estimated from the data by means of fitting. 
- ploidy, that defines the types of peaks and the need for a peak proportion. 


```{r}

```


